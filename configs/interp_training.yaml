# LayeredInterpolator Training Configuration
# ============================================
# Optimized for RTX 5070 Ti (16GB VRAM)

# Model Architecture
base_channels: 32        # Base feature channels (doubled at each level)
kernel_size: 7           # AdaCoF kernel size (KÃ—K)
grid_size: 8             # Background affine grid size
use_refinement: true     # Use refinement U-Net in compositor

# Discriminator
disc_channels: 64        # Base discriminator channels

# Training
epochs: 30               # Reduced from 100 (most learning in early epochs)
batch_size: 12           # Maximum for 5070 Ti 16GB VRAM (~14GB usage estimated)
num_workers: 12          # High parallelism for fast data loading
crop_size: [256, 256]    # Random crop size for training
prefetch_factor: 4       # Prefetch batches per worker
persistent_workers: true # Keep workers alive between epochs
max_samples: 100000      # Limit dataset size for faster training (~3.5 days)

# Learning rates
lr_g: 0.0001             # Generator learning rate
lr_d: 0.0001             # Discriminator learning rate
weight_decay: 0.01       # AdamW weight decay

# Loss weights
l1_weight: 1.0           # L1 reconstruction loss
perceptual_weight: 0.1   # VGG perceptual loss
edge_weight: 0.5         # Edge-weighted L1 loss
gan_weight: 0.01         # Adversarial loss weight

# GAN configuration
gan_type: lsgan          # 'vanilla', 'lsgan', or 'hinge'

# Mixed precision
use_amp: true            # Use automatic mixed precision (FP16)
cudnn_benchmark: true    # Enable cuDNN auto-tuner for faster training

# Logging and checkpointing
log_dir: runs
checkpoint_dir: checkpoints
save_every: 1            # Save checkpoint every epoch
save_every_batches: 1000 # Also save every N batches (0 to disable)

# Data
data_dir: D:\Triplets    # Path to triplet dataset

